{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "\n",
    "Let's start with some data that will give us examples\n",
    "of the kind of classes we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package senseval to /Users/gawron/nltk_data...\n",
      "[nltk_data]   Package senseval is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('senseval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import senseval\n",
    "\n",
    "hard_data = [(i,i.senses[0]) for i in senseval.instances('hard.pos')]\n",
    "\n",
    "len(hard_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have downloaded some data with over 4,000 examples!  Looking at the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SensevalInstance(word='hard-a', position=20, context=[('``', '``'), ('he', 'PRP'), ('may', 'MD'), ('lose', 'VB'), ('all', 'DT'), ('popular', 'JJ'), ('support', 'NN'), (',', ','), ('but', 'CC'), ('someone', 'NN'), ('has', 'VBZ'), ('to', 'TO'), ('kill', 'VB'), ('him', 'PRP'), ('to', 'TO'), ('defeat', 'VB'), ('him', 'PRP'), ('and', 'CC'), ('that', 'DT'), (\"'s\", 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('.', '.'), (\"''\", \"''\")], senses=('HARD1',)),\n",
       " 'HARD1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " hard_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a data structure (a Python object) with an attribute called `context` that contains a awkwardky respresented sentence, because each word is paired with a part of speech tag. Here are the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`` he may lose all popular support , but someone has to kill him to defeat him and that 's hard to do . ''\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([word for (word,tag) in hard_data[0][0].context]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we created  `hard_data` was to write a Python **list comprehension** (a kind of \n",
    "abbreviated `for`-loop) that returned a list of pairs. As a result,\n",
    "the first member of the list, `hard_data[0]`, is a **pair**. Let's  \n",
    "look at the two objects in the pair::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARD1 SensevalInstance(word='hard-a', position=20, context=[('``', '``'), ('he', 'PRP'), ('may', 'MD'), ('lose', 'VB'), ('all', 'DT'), ('popular', 'JJ'), ('support', 'NN'), (',', ','), ('but', 'CC'), ('someone', 'NN'), ('has', 'VBZ'), ('to', 'TO'), ('kill', 'VB'), ('him', 'PRP'), ('to', 'TO'), ('defeat', 'VB'), ('him', 'PRP'), ('and', 'CC'), ('that', 'DT'), (\"'s\", 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('.', '.'), (\"''\", \"''\")], senses=('HARD1',))\n"
     ]
    }
   ],
   "source": [
    "ex0 = hard_data[0]\n",
    "cls,si = ex0[1],ex0[0]\n",
    "print(cls,si)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HARD1` is the class which we are trying to  learn to predict in this classification\n",
    "task.  The other member of the pair contains the data\n",
    "we're going try to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name I chose, `si`, stands for for \"senseval instance\".  This a Python\n",
    "**object** (a special user-defined custom data type), that stores information\n",
    "appropriate to the data in this corpus.  An `si`-instance has\n",
    "two attributes of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', '``'),\n",
       " ('he', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('lose', 'VB'),\n",
       " ('all', 'DT'),\n",
       " ('popular', 'JJ'),\n",
       " ('support', 'NN'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('someone', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('kill', 'VB'),\n",
       " ('him', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('defeat', 'VB'),\n",
       " ('him', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'DT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('hard', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('.', '.'),\n",
       " (\"''\", \"''\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hard-a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute context has a sentence which contains the word\n",
    "`si.word` (`hard-a`, or the adjective \"hard\") somewhere in it\n",
    "(the actual position of `si.word` is stored in `si.position`). Notice\n",
    "the \"words\" in the sentence are actually pairs of a word and a part of\n",
    "speech tag.  We will learn more about such tags later in the\n",
    "course. For now `VB`, `VBZ`, `VBD`, and `VBG` are all kinds of verbs,\n",
    "and `NN`, `NNS`, `NNP`, and `NNPSS` are all kinds of nouns.  For the\n",
    "purposes of this exercise, the difference between a word and a\n",
    "word/part of speech pair does not matter.  We will be counting\n",
    "word/part of speech pairs instead of words.\n",
    "\n",
    "Our task is to learn how to predict the sense\n",
    "of any token of the adjective *hard* based on the words\n",
    "in the sentence it occurs in.  To make\n",
    "a prediction, we will use all the words in the training set,\n",
    "and we will use a Naive-Bayes classifier to choose a sense.\n",
    "Let's store the list of senses we need to choose between\n",
    "under the name `senses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HARD1', 'HARD2', 'HARD3']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses = sorted(list(set(sense for (inst, sense) in hard_data)))\n",
    "senses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are only 3 senses.  Let's get an idea of what their definitions\n",
    "are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_examples(data, sense, num_examples):\n",
    "    res = []\n",
    "    for (inst,s) in data:\n",
    "        if s == sense:\n",
    "         res.append(inst)\n",
    "        if len(res) == num_examples:\n",
    "         return res\n",
    "\n",
    "def print_examples (ex_list):\n",
    "    for ex in ex_list:\n",
    "        for word in ex.context:\n",
    "          print('{0}_{1}'.format(word[0], word[1]), sep = ' ', end=' ')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab some examples of each sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard1_ex = find_examples(hard_data, 'HARD1', 3)\n",
    "hard2_ex = find_examples(hard_data, 'HARD2', 3)\n",
    "hard3_ex = find_examples(hard_data, 'HARD3', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some examples of sense `HARD1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "``_`` he_PRP may_MD lose_VB all_DT popular_JJ support_NN ,_, but_CC someone_NN has_VBZ to_TO kill_VB him_PRP to_TO defeat_VB him_PRP and_CC that_DT 's_VBZ hard_JJ to_TO do_VB ._. ''_'' \n",
      "\n",
      "clever_NNP white_NNP house_NNP ``_`` spin_VB doctors_NNS ''_'' are_VBP having_VBG a_DT hard_JJ time_NN helping_VBG president_NNP bush_NNP explain_VB away_RB the_DT economic_JJ bashing_NN that_IN low-and_JJ middle-income_JJ workers_NNS are_VBP taking_VBG these_DT days_NNS ._. \n",
      "\n",
      "i_PRP find_VBP it_PRP hard_JJ to_TO believe_VB that_IN the_DT sacramento_NNP river_NNP will_MD ever_RB be_VB quite_RB the_DT same_JJ ,_, although_IN i_PRP certainly_RB wish_VBP that_IN i_PRP 'm_VBP wrong_JJ ._. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_examples(hard1_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this sense could be paraphrased as \"difficult\".  And it looks like\n",
    "the word `time` might be one good cue for this sense.\n",
    "\n",
    "And now `hard2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_VB this_DT one_CD in_IN your_PRP$ drawer_NN for_IN the_DT next_JJ time_NN the_DT boss_NN gives_VBZ you_PRP a_DT hard_JJ time_NN ._. \n",
      "\n",
      "she_PRP recommends_VBZ continuing_VBG education_NN courses_NNS ,_, developing_VBG effective_JJ people_NNS skills_NNS and_CC hard_JJ work_NN ._. \n",
      "\n",
      "the_DT phrase_NN ``_`` consent_NN of_IN the_DT governed_VBN ''_'' needs_VBZ a_DT hard_JJ look_NN ._. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_examples (hard2_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paraphrase this one as \"stressful\" or \"intense\".  And finally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_PRP$ companion_NN enjoyed_VBD a_DT healthy_JJ slice_NN of_IN the_DT chocolate_NN mousse_NN cake_NN ,_, made_VBN with_IN a_DT hard_JJ chocolate_NN crust_NN ,_, topping_VBG a_DT sponge_NN cake_NN with_IN either_DT strawberry_NN or_CC raspberry_JJ on_IN the_DT bottom_NN ._. \n",
      "\n",
      "``_`` i_PRP feel_VBP that_IN the_DT hard_JJ court_NN is_VBZ my_PRP$ best_JJS surface_NN overall_JJ ,_, \"_\" courier_NNP said_VBD ._. \n",
      "\n",
      "water_NNP becomes_VBZ stiff_JJ and_CC hard_JJ as_IN clear_JJ stone_NN ._. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_examples (hard3_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So this sense could be paraphrased \"the opposite of **soft**\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We need to separate training and test data. \n",
    "\n",
    "First let's shuffle our data instances.  They're a little\n",
    "too orderly and we need to make a fair test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle   \n",
    "new_hard_data = shuffle(hard_data, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This probably won't work across machines, but I'm\n",
    "hoping your results more closely match mine if you\n",
    "use the same value for the random_state argument (42) as I do.\n",
    "\n",
    "\n",
    "We're going to do a Naive Bayes model that\n",
    "tells us what sense of **hard** is being used\n",
    "in  sentences in our corpus.  We need to separate\n",
    "a bundle to train on and another smaller bundle to \n",
    "test on::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = int(9 * round(len(hard_data)/10.))\n",
    "train_data = new_hard_data[:train_ind]\n",
    "test_data = new_hard_data[train_ind:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the total amount of training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3897"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(train_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly 4000 examples.\n",
    "\n",
    "Now let's use a Python dictionary to\n",
    "sort our training data into the three senses. These are\n",
    "three **classes** that we are learning to recognize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dict((sense,[]) for sense in senses)\n",
    "for (s_inst, sense) in  train_data:\n",
    "    train_dict[sense].append(s_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARD1 3100\n",
      "HARD2 459\n",
      "HARD3 338\n",
      "Total 3897\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for sense in senses:\n",
    "    inc = len(train_dict[sense])\n",
    "    ctr += inc\n",
    "    print(sense, inc)\n",
    "print('Total', ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target word *hard* occurs only once in each sentence,\n",
    "we computed the number of instances of each sense by\n",
    "counting the number of sentences in each data class:\n",
    "By the same reasoning, the total number of tokens of the word\n",
    "*hard* is the total number of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to start counting words in a single context example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "si0 = train_dict[senses[0]][0]\n",
    "fd = nltk.FreqDist()\n",
    "fd.update(si0.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('to', 'TO'): 2, ('it', 'PRP'): 1, ('was', 'VBD'): 1, ('so', 'RB'): 1, ('hard', 'JJ'): 1, ('shoot', 'VB'): 1, (',', ','): 1, ('we', 'PRP'): 1, ('lost', 'VBD'): 1, ('our', 'PRP$'): 1, ...})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the words in the context sentence now have count 1.\n",
    "Okay, now another sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('to', 'TO'): 3, ('it', 'PRP'): 2, ('hard', 'JJ'): 2, (',', ','): 2, ('n', 'NN'): 2, (\"'t\", 'NN'): 2, ('of', 'IN'): 2, ('.', '.'): 2, ('was', 'VBD'): 1, ('so', 'RB'): 1, ...})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si1 = train_dict[senses[0]][1]\n",
    "fd.update(si1.context)\n",
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crucially counts are getting **incremented** by the `update`\n",
    "method.  Now many words have counts of 2 and 3.\n",
    "Based on that, here's a loop which computes, for each term\n",
    "(word) $t_{i}$, the number of  times $t_{i}$ occurs in\n",
    "a sentence in the  data for a particular sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_dict = dict()\n",
    "for sense in senses:\n",
    "    fd_dict[sense] = nltk.FreqDist()\n",
    "    for si in train_dict[sense]:\n",
    "        fd_dict[sense].update(si.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fd_dict['HARD1']` is now a dictionary which,\n",
    "for each word key `w`, returns the number of times \n",
    "that word `w` occurred in a sentence with sense `HARD1`.\n",
    "To look up $\\text{count}(t_{k}, s)$, where \n",
    "$t_{k} = (\\text{time}, \\text{NN})$ and\n",
    "$s = \\text{HARD1}$, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_dict['HARD1'][('time','NN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of tokens of the word \"time\" occuring (as a noun) in sentences with\n",
    "sense `HARD1` is 293.  \n",
    "\n",
    "The total number of word tokens occurring\n",
    "in sentences with sense `HARD1` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79228"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_dict['HARD1'].N()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have done that, you basically have a trained\n",
    "Naive Bayes model.  For each class $s$, you know\n",
    "how to compute $P(s)$.\n",
    "\n",
    "For example, to compute $p(\\text{HARD1})$, the probability of the HARD1 sense,\n",
    "you need to know the total number \n",
    "the number of tokens of \"hard\" that\n",
    "occured with sense `HARD1` in the training data and you need\n",
    "know the number of tokens of the word \"hard\" in all senses. Therefore,\n",
    "\n",
    "$p(\\text{HARD1}) = \\frac{\\text{count}(\\text{HARD1},\\, \\text{\"hard\"})}{\\sum_{s} \\text{count}(s, \\,\\text{\"hard\"})}$\n",
    "\n",
    "The other Naive Bayes parameters is the conditional probabilities\n",
    "of the words given the senses:  that is, for each sense $s$,\n",
    "for each term $t_k$, we need $P(t_{k} \\mid s)$.\n",
    "For this, the additional count needed for an MLE estimate\n",
    "is the count of each word with each sense, $\\text{count}(t_{k}, s)$.\n",
    "Then for each **word** $t_{k}$ and each sense $s$:\n",
    "\n",
    "${P}_{\\text{mle}}(t_{k} \\mid s) = \\frac{\\text{count}(t_{k}, s)}{\\sum_{j} \\text{count}(t_{j}, s)}$\n",
    "\n",
    "We just saw how to look up $\\text{count}(t_{k}, s)$.  Now the denominator is a sum. It sums up $\\text{count}(t_{k}, s)$ for every word in the\n",
    "vocabulary; and that sum is just the total number of word tokens occurring\n",
    "in sentences with sense $s$.  We computed that for `HARD1` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing\n",
    "\n",
    "The first step in smoothing is as simple as can be.  We basically\n",
    "have three vocabularies compiled, one for each of three senses. \n",
    "We need a total vocabulary\n",
    "that is the union of all three::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_V = set(list(fd_dict['HARD1'].keys()) + list(fd_dict['HARD2'].keys()) + \n",
    "               list(fd_dict['HARD3'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do add1 smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_fd_dict = dict() \n",
    "for sense in senses:\n",
    "    sm_fd = nltk.FreqDist()\n",
    "    fd = fd_dict[sense]\n",
    "    sm_fd_dict[sense] = sm_fd\n",
    "    for word in total_V:\n",
    "          sm_fd[word] = fd[word] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever `word` `t` did not occur with sense `HARD1`, `sm_fd_dict['HARD1'][t]` will\n",
    "return the count 0, and the smoothed count will be 1; as a result no\n",
    "word in `total_V` will have a count of 0 in `sm_fd_dict['HARD1']`.  It is now\n",
    "easy to find the new **smoothed count** of the total number of words\n",
    "\"occurring\" in sentences with sense `HARD1`.  That is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92735"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_fd_dict['HARD1'].N()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which has gone up because it now assigns\n",
    "count1 to all the words that never occurred \n",
    "with sense `HARD1` in the training. \n",
    "\n",
    "As a result the toatl word counts and the probability of\n",
    "each sense will change slightly. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\text{HARD1}) = \\frac{\\text{sm_count}(\\text{HARD1},\\, \\text{\"hard\"})}{\\sum_{s} \\text{sm_count}(s, \\,\\text{\"hard\"})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Turn in a copy of this notebook with answers to the following questions.  You \n",
    "should include as an appendix, and cells containing the code you executed\n",
    "to get your answers.  The material above is intended to help\n",
    "you produce that code.  Numbers given with\n",
    "no evidence of how you got them code will not be accepted.\n",
    "That evidence cannot just be a count to be accepted on faith.\n",
    "For every count you use in a probability calcylation, smoothed\n",
    "or unsmoothed, you must show how you got that count\n",
    "from the data above.  You should use the code examples provided\n",
    "above as yo ur guide for how to look up and interpret the data.\n",
    "\n",
    "Note that question 2 involves some multiplication of\n",
    "really, really tiny probabilities to get\n",
    "the joint probability of the sense and the whole sentence.  \n",
    "If you know a little Python you\n",
    "can write a very simple loop.  It will begin::\n",
    "\n",
    "```\n",
    "for word in t0:\n",
    "    prob *= < some stuff >\n",
    "```\n",
    "That is, multiply the current value of `prob` by < some stuff >,\n",
    "and update the value of `prob` to be equal to the result.  Each word\n",
    "you look at introduces another factor; and since they will\n",
    "all be less than 1, `prob` keeps getting smaller and smaller.\n",
    "If you don't feel comfortable writing the Python loop, you can write\n",
    "out the sequence of multiplications by hand.  I have chosen\n",
    "very short sentences to allow you to do just that.\n",
    "\n",
    "  1. Compute $\\hat{P}(\\text{HARD1})$.   Compute $\\hat{P}(\\text{HARD2})$. Compute $\\hat{P}(\\text{HARD3})$. Note:  \n",
    "     $P(\\text{HARD1})$ is the **prior probability**  of sense `HARD1`\n",
    "     (See slide 3 of the \n",
    "     [Naive Bayes lectures slides](http://gawron.sdsu.edu/compling/course_core/lectures/naive_bayes.pdf>).  $\\hat{P}(\\text{'HARD1'})$ is estimated\n",
    "     prior probability. (See slide 7).\n",
    "\n",
    "     One way to test that you are doing this right is to check: $\\hat{P}(\\text{HARD1}) + \\hat{P}(\\text{HARD2}) +\\hat{P}(\\text{HARD3})$\n",
    "\n",
    "     You should get 1.0.\n",
    "\n",
    "  2. For this question, use the definition of  the \n",
    "     probability of the sense and the document \n",
    "     on slide 6, illustrated in the example\n",
    "     on slide 19: \n",
    "     \n",
    "     $$\\hat{P}(s) \\prod_{1 \\leq k \\leq n_d} \\hat{P}(t_{k} \\mid s)$$\n",
    "\n",
    "     Assume the document is\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " t0 = [('it', 'PRP'), (\"'s\", 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('watch', 'VB'), \n",
    "       ('.', '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2. Here the document size $n_d$ will be 5 (because we're omitting the target word\n",
    "     `('hard', 'JJ')`). Compute the following joint probability:\n",
    "     \n",
    "      $$\\hat{P}(\\text{HARD1}) \\prod_{1 \\leq k \\leq 5} \\hat{P}(t_{k} \\mid \\text{HARD1})$$\n",
    "      \n",
    " \n",
    "  3.  Same question as (2.) for HARD2 and HARD3. The results should provide\n",
    "      motivation for answering the next question, which is about smoothing.  \n",
    "      Explain what happened and determine what words in the context motivated \n",
    "      smoothing.  But despite the smoothing issues, based on the numbers\n",
    "      you get, what is the maximum a posteriori class?  That is,\n",
    "      what **sense** does  Naive Bayes choose?\n",
    "\n",
    "  4.  Now create\n",
    "      a smoothed model using add 1 smoothing, as defined in slide 12,\n",
    "      and illustrated in slide 18.  Recompute the joint\n",
    "      probability for the data you were given in question 2, \n",
    "      and report the classification decision made\n",
    "      by the smoothed model.\n",
    "\n",
    "  5. Estimate $\\hat{P}(\\text{HARD1} \\mid t_{1,n_{d}})$ for the\n",
    "     sentence in question (2) using the unsmoothed model.  You\n",
    "     will need to normalize the probability.  See slide 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
